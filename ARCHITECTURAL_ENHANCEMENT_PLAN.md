# F1 Analytics Dashboard - Architectural Enhancement Plan

**Generated by Senior Architect Skill** | Date: 2026-02-02

## Executive Summary

The F1 Analytics Dashboard is a Streamlit-based web application for analyzing Formula 1 telemetry and race data. Current architecture is functional but lacks modularity, performance optimization, and enterprise-grade patterns. This plan outlines a comprehensive enhancement strategy using modern architecture patterns.

---

## Current State Assessment

### Strengths âœ…
- Clear user interface with intuitive navigation
- Effective use of Streamlit for rapid prototyping
- Integration with FastF1 data source
- Plotly for interactive visualizations
- Modular UI sections (Overview, Driver Analysis, Telemetry, AI Insights)
- Caching mechanisms for performance

### Weaknesses âš ï¸
1. **Monolithic Structure**: All code in single `app.py` file (391 lines)
2. **No separation of concerns**: UI, data fetching, and business logic mixed
3. **Limited error handling**: Broad try-catch blocks without specific recovery
4. **Hardcoded values**: Session types, cache paths, UI styling duplicated
5. **No logging**: Difficult to debug issues in production
6. **Incomplete AI features**: Placeholder sections without implementation
7. **No state management**: Session state scattered throughout
8. **No testing infrastructure**: Zero test coverage
9. **Missing documentation**: No API or module documentation
10. **No performance monitoring**: No metrics or profiling

---

## Recommended Architecture: Layered + Services Pattern

```
f1-project/
â”œâ”€â”€ app.py                          # Entry point (minimal)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py                # Configuration management
â”‚   â””â”€â”€ constants.py               # Hardcoded constants
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ f1_data_service.py         # FastF1 interactions
â”‚   â”œâ”€â”€ cache_service.py           # Cache management
â”‚   â”œâ”€â”€ telemetry_service.py       # Telemetry analysis
â”‚   â””â”€â”€ ai_service.py              # ML/AI predictions
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ session.py                 # Session data model
â”‚   â”œâ”€â”€ driver.py                  # Driver model
â”‚   â””â”€â”€ telemetry.py               # Telemetry model
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ overview.py            # Overview tab
â”‚   â”‚   â”œâ”€â”€ driver_analysis.py     # Driver comparison tab
â”‚   â”‚   â”œâ”€â”€ telemetry.py           # Telemetry tab
â”‚   â”‚   â””â”€â”€ ai_insights.py         # AI Insights tab
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py             # Metric cards
â”‚   â”‚   â”œâ”€â”€ charts.py              # Chart components
â”‚   â”‚   â””â”€â”€ sidebar.py             # Sidebar component
â”‚   â””â”€â”€ styles.py                  # Centralized styling
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                  # Logging configuration
â”‚   â”œâ”€â”€ exceptions.py              # Custom exceptions
â”‚   â”œâ”€â”€ decorators.py              # Common decorators
â”‚   â””â”€â”€ validators.py              # Input validation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_services.py
â”‚   â”œâ”€â”€ test_ui.py
â”‚   â””â”€â”€ fixtures/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md                     # API documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md            # Architecture guide
â”‚   â””â”€â”€ DEVELOPMENT.md             # Developer guide
â””â”€â”€ requirements.txt
```

---

## Phase 1: Foundation & Modularization (Week 1-2)

### 1.1 Configuration Management

**File**: `config/settings.py`

```python
"""Application configuration management"""
from pathlib import Path
from typing import Dict, Any
import json
import os

class Settings:
    """Central configuration for the application"""
    
    # Paths
    BASE_DIR = Path(__file__).parent.parent
    CACHE_DIR = Path.home() / '.fastf1-cache'
    
    # FastF1 Settings
    FASTF1_ENABLE_CACHE = True
    FASTF1_SEASON_START = 2018
    
    # Streamlit Settings
    PAGE_CONFIG = {
        'page_title': 'F1 Analytics Dashboard | nexairi.com',
        'page_icon': 'ðŸŽï¸',
        'layout': 'wide',
        'initial_sidebar_state': 'expanded'
    }
    
    # UI Settings
    UI_COLORS = {
        'primary_red': '#e10600',
        'primary_red_light': '#ff1801',
        'text_secondary': '#666',
        'background_light': '#f0f2f6'
    }
    
    # Session Types
    SESSION_TYPES = {
        'Race': 'R',
        'Qualifying': 'Q',
        'Practice 1': 'FP1',
        'Practice 2': 'FP2',
        'Practice 3': 'FP3',
        'Sprint': 'S',
        'Sprint Qualifying': 'SQ'
    }
    
    # Cache TTL (in seconds)
    CACHE_SCHEDULE_TTL = 3600  # 1 hour
    CACHE_SESSION_TTL = 7200   # 2 hours
    
    @classmethod
    def validate(cls) -> bool:
        """Validate configuration"""
        cls.CACHE_DIR.mkdir(exist_ok=True)
        return True

# Singleton instance
settings = Settings()
```

### 1.2 Logging Infrastructure

**File**: `utils/logger.py`

```python
"""Logging configuration"""
import logging
import sys
from pathlib import Path
from datetime import datetime

def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """Configure application logger"""
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # Console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    
    # Format
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    console_handler.setFormatter(formatter)
    
    logger.addHandler(console_handler)
    return logger

# Application logger
logger = setup_logger(__name__)
```

### 1.3 Exception Handling

**File**: `utils/exceptions.py`

```python
"""Custom exceptions"""

class F1DashboardException(Exception):
    """Base exception for F1 Dashboard"""
    pass

class DataLoadException(F1DashboardException):
    """Raised when data cannot be loaded"""
    pass

class CacheException(F1DashboardException):
    """Raised when cache operations fail"""
    pass

class ValidationException(F1DashboardException):
    """Raised when validation fails"""
    pass

class SessionDataException(F1DashboardException):
    """Raised when session data is invalid"""
    pass
```

---

## Phase 2: Service Layer (Week 2-3)

### 2.1 F1 Data Service

**File**: `services/f1_data_service.py`

```python
"""FastF1 data operations"""
import fastf1
import pandas as pd
from datetime import datetime
from typing import Optional, Dict, Any
import streamlit as st
from pathlib import Path

from config.settings import settings
from utils.logger import logger
from utils.exceptions import DataLoadException, CacheException

class F1DataService:
    """Service for FastF1 data operations"""
    
    def __init__(self):
        self._initialize_cache()
    
    def _initialize_cache(self) -> None:
        """Initialize FastF1 caching"""
        try:
            settings.CACHE_DIR.mkdir(exist_ok=True)
            fastf1.Cache.enable_cache(str(settings.CACHE_DIR))
            logger.info(f"Cache enabled at {settings.CACHE_DIR}")
        except Exception as e:
            logger.error(f"Failed to initialize cache: {e}")
            raise CacheException(f"Cache initialization failed: {e}")
    
    @st.cache_data(ttl=settings.CACHE_SCHEDULE_TTL)
    def get_schedule(self, year: int) -> Optional[pd.DataFrame]:
        """Fetch F1 schedule for given year"""
        try:
            logger.info(f"Fetching schedule for {year}")
            schedule = fastf1.get_event_schedule(year)
            
            # Filter to past/current races
            today = pd.Timestamp.now()
            available = schedule[schedule['EventDate'] <= today]
            
            logger.info(f"Found {len(available)} available races in {year}")
            return available
        except Exception as e:
            logger.error(f"Failed to load schedule for {year}: {e}")
            raise DataLoadException(f"Cannot load schedule: {e}")
    
    @st.cache_data(ttl=settings.CACHE_SESSION_TTL)
    def get_session(self, year: int, round_num: int, session_type: str) -> Optional[Any]:
        """Fetch F1 session data"""
        try:
            logger.info(f"Fetching {session_type} session for R{round_num}/{year}")
            session = fastf1.get_session(year, round_num, session_type)
            session.load()
            logger.info(f"Successfully loaded session")
            return session
        except Exception as e:
            logger.error(f"Failed to load session: {e}")
            raise DataLoadException(f"Cannot load session: {e}")
    
    def get_session_results(self, session: Any) -> pd.DataFrame:
        """Extract results from session"""
        try:
            return pd.DataFrame({
                'Position': session.results['Position'],
                'Driver': session.results['Abbreviation'],
                'Team': session.results['TeamName'],
                'Time': session.results['Time'],
                'Status': session.results['Status'],
                'Points': session.results['Points']
            })
        except Exception as e:
            logger.error(f"Failed to extract results: {e}")
            raise DataLoadException(f"Cannot extract results: {e}")

# Singleton
data_service = F1DataService()
```

### 2.2 Telemetry Service

**File**: `services/telemetry_service.py`

```python
"""Telemetry analysis operations"""
import pandas as pd
from typing import Optional, Tuple
import plotly.graph_objects as go
import plotly.express as px
from utils.logger import logger

class TelemetryService:
    """Service for telemetry analysis"""
    
    @staticmethod
    def get_driver_laps(session: Any, driver: str) -> pd.DataFrame:
        """Get all laps for a driver"""
        try:
            logger.info(f"Fetching laps for driver {driver}")
            laps = session.laps.pick_driver(driver)
            logger.info(f"Found {len(laps)} laps")
            return laps
        except Exception as e:
            logger.error(f"Failed to get driver laps: {e}")
            raise
    
    @staticmethod
    def create_lap_comparison_chart(driver1_laps: pd.DataFrame, driver2_laps: pd.DataFrame, 
                                     driver1_name: str, driver2_name: str) -> go.Figure:
        """Create lap time comparison chart"""
        try:
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=driver1_laps['LapNumber'],
                y=driver1_laps['LapTime'].dt.total_seconds(),
                mode='lines+markers',
                name=driver1_name,
                line=dict(width=2)
            ))
            
            fig.add_trace(go.Scatter(
                x=driver2_laps['LapNumber'],
                y=driver2_laps['LapTime'].dt.total_seconds(),
                mode='lines+markers',
                name=driver2_name,
                line=dict(width=2)
            ))
            
            fig.update_layout(
                xaxis_title="Lap Number",
                yaxis_title="Lap Time (seconds)",
                hovermode='x unified',
                height=400
            )
            
            return fig
        except Exception as e:
            logger.error(f"Failed to create comparison chart: {e}")
            raise
    
    @staticmethod
    def create_speed_trace(telemetry: pd.DataFrame, driver: str, lap_num: int) -> go.Figure:
        """Create speed trace chart"""
        fig = px.line(telemetry, x='Distance', y='Speed',
                     title=f"{driver} - Lap {lap_num} Speed")
        fig.update_xaxis(title="Distance (m)")
        fig.update_yaxis(title="Speed (km/h)")
        return fig
    
    @staticmethod
    def create_controls_chart(telemetry: pd.DataFrame) -> go.Figure:
        """Create throttle and brake chart"""
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=telemetry['Distance'],
            y=telemetry['Throttle'],
            mode='lines',
            name='Throttle',
            fill='tozeroy',
            line=dict(color='green')
        ))
        
        fig.add_trace(go.Scatter(
            x=telemetry['Distance'],
            y=telemetry['Brake'],
            mode='lines',
            name='Brake',
            fill='tozeroy',
            line=dict(color='red')
        ))
        
        fig.update_xaxis(title="Distance (m)")
        fig.update_yaxis(title="Input (%)")
        return fig

# Singleton
telemetry_service = TelemetryService()
```

---

## Phase 3: UI Layer Refactoring (Week 3-4)

### 3.1 Centralized Styles

**File**: `ui/styles.py`

```python
"""Centralized styling"""
from config.settings import settings

def get_custom_css() -> str:
    """Get custom CSS for application"""
    colors = settings.UI_COLORS
    return f"""
    <style>
    .main-header {{
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(90deg, {colors['primary_red']} 0%, {colors['primary_red_light']} 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.5rem;
    }}
    .subtitle {{
        color: {colors['text_secondary']};
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }}
    .metric-card {{
        background: {colors['background_light']};
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid {colors['primary_red']};
    }}
    </style>
    """
```

### 3.2 Sidebar Component

**File**: `ui/components/sidebar.py`

```python
"""Sidebar component"""
import streamlit as st
from typing import Tuple, Dict
from config.settings import settings
from services.f1_data_service import data_service
from utils.logger import logger

class SidebarComponent:
    """Sidebar selection component"""
    
    @staticmethod
    def render() -> Tuple[int, str, int]:
        """Render sidebar and return selections"""
        with st.sidebar:
            st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/F1.svg/1200px-F1.svg.png", 
                    width=150)
            st.markdown("## ðŸ Select Race")
            
            # Year selection
            from datetime import datetime
            current_year = datetime.now().year
            year = st.selectbox(
                "Season",
                options=list(range(current_year, settings.FASTF1_SEASON_START - 1, -1)),
                index=0
            )
            
            # Session type
            session_type = st.radio(
                "Session Type",
                options=list(settings.SESSION_TYPES.keys()),
                index=0
            )
            
            st.markdown("---")
            
            # Load schedule
            try:
                schedule = data_service.get_schedule(year)
                if schedule is None or len(schedule) == 0:
                    st.warning(f"No races available for {year}")
                    return None
                
                race_options = {
                    f"Round {row['RoundNumber']}: {row['EventName']} ({row['Country']})": 
                    int(row['RoundNumber'])
                    for _, row in schedule.iterrows()
                }
                
                selected_race = st.selectbox("Grand Prix", options=list(race_options.keys()))
                round_number = race_options[selected_race]
                
                return year, session_type, round_number
            except Exception as e:
                logger.error(f"Sidebar error: {e}")
                st.error("Failed to load race data")
                return None
```

---

## Phase 4: AI/ML Integration (Week 4-5)

### 4.1 AI Service

**File**: `services/ai_service.py`

```python
"""AI and ML predictions"""
import pandas as pd
from typing import Dict, Any, List
from utils.logger import logger

class AIService:
    """AI-powered analytics and predictions"""
    
    @staticmethod
    def predict_race_winner(quali_data: pd.DataFrame) -> Dict[str, float]:
        """Predict race winner based on qualifying results"""
        try:
            logger.info("Computing race winner prediction")
            # TODO: Implement ML model
            # Placeholder: weight quali position
            predictions = {}
            for idx, row in quali_data.iterrows():
                score = 1.0 / (row['Position'] + 1)
                predictions[row['Driver']] = score
            
            # Normalize
            total = sum(predictions.values())
            return {k: v/total for k, v in predictions.items()}
        except Exception as e:
            logger.error(f"Race winner prediction failed: {e}")
            raise
    
    @staticmethod
    def analyze_pit_strategy(session: Any) -> List[Dict[str, Any]]:
        """Analyze optimal pit strategies"""
        try:
            logger.info("Analyzing pit strategies")
            # TODO: Implement strategy analyzer
            return []
        except Exception as e:
            logger.error(f"Pit strategy analysis failed: {e}")
            raise
    
    @staticmethod
    def compute_performance_rating(driver_laps: pd.DataFrame) -> float:
        """Compute driver performance rating"""
        try:
            if driver_laps.empty:
                return 0.0
            
            fastest = driver_laps['LapTime'].min()
            avg = driver_laps['LapTime'].mean()
            consistency = (avg / fastest) - 1  # Delta from fastest
            
            # Score: 100 for fastest, decreases with inconsistency
            rating = max(0, 100 - (consistency * 50))
            return rating
        except Exception as e:
            logger.error(f"Performance rating computation failed: {e}")
            return 0.0

ai_service = AIService()
```

---

## Phase 5: Testing Infrastructure (Week 5)

### 5.1 Test Setup

**File**: `tests/conftest.py`

```python
"""Pytest configuration"""
import pytest
import pandas as pd

@pytest.fixture
def sample_schedule():
    """Sample F1 schedule"""
    return pd.DataFrame({
        'RoundNumber': [1, 2, 3],
        'EventName': ['Bahrain', 'Saudi Arabia', 'Australia'],
        'Country': ['Bahrain', 'Saudi Arabia', 'Australia'],
        'EventDate': pd.date_range('2024-01-01', periods=3, freq='W')
    })
```

### 5.2 Service Tests

**File**: `tests/test_services.py`

```python
"""Service tests"""
import pytest
from services.telemetry_service import telemetry_service

def test_compute_performance_rating():
    """Test performance rating computation"""
    import pandas as pd
    from datetime import timedelta
    
    laps = pd.DataFrame({
        'LapTime': pd.TimedeltaIndex([
            timedelta(seconds=90),
            timedelta(seconds=91),
            timedelta(seconds=89),
            timedelta(seconds=92)
        ]),
        'LapNumber': [1, 2, 3, 4]
    })
    
    rating = telemetry_service.compute_performance_rating(laps)
    assert 0 <= rating <= 100
    assert rating > 0  # Should have valid rating
```

---

## Phase 6: Documentation (Week 6)

### 6.1 API Documentation

**File**: `docs/API.md`

Document all services, models, and utilities.

### 6.2 Architecture Guide

**File**: `docs/ARCHITECTURE.md`

Explain design decisions, patterns used, and rationale.

---

## Implementation Priorities

| Priority | Phase | Items | Timeline |
|----------|-------|-------|----------|
| P0 - Critical | 1 | Configuration, Logging, Exceptions | Week 1 |
| P1 - High | 2 | Service Layer (Data, Telemetry) | Week 2-3 |
| P2 - Medium | 3 | UI Refactoring, Components | Week 3-4 |
| P3 - Enhancement | 4 | AI/ML Features | Week 4-5 |
| P4 - Quality | 5 | Testing, Documentation | Week 5-6 |

---

## Key Improvements Summary

### Code Quality
- âœ… Modular architecture
- âœ… Single responsibility principle
- âœ… Comprehensive error handling
- âœ… Logging and monitoring
- âœ… Type hints throughout
- âœ… Test coverage

### Performance
- âœ… Optimized caching strategies
- âœ… Lazy loading of data
- âœ… Efficient data processing
- âœ… Resource monitoring

### Maintainability
- âœ… Clear separation of concerns
- âœ… Comprehensive documentation
- âœ… Consistent naming conventions
- âœ… Easy to extend and modify

### User Experience
- âœ… Faster load times
- âœ… Better error messages
- âœ… More responsive UI
- âœ… AI-powered insights

---

## Technology Stack Recommendations

### Current
- Streamlit 1.31+
- FastF1 3.3+
- Pandas 2.0+
- Plotly 5.18+

### Recommended Additions
- **Logging**: Python's `logging` module (built-in)
- **Type Checking**: Pydantic for validation
- **Testing**: pytest + pytest-cov
- **ML**: scikit-learn, TensorFlow (for AI features)
- **Monitoring**: Prometheus (optional for production)

---

## Deployment Considerations

### Development
```bash
streamlit run app.py
```

### Production
- Use Streamlit Cloud or Docker
- Enable environment-based configuration
- Implement rate limiting
- Add monitoring and alerting
- Use production database for session storage

---

## Conclusion

This architectural enhancement plan transforms the F1 Analytics Dashboard from a functional prototype into a production-ready, maintainable, and scalable application. By following the phased approach, you can incrementally improve the codebase while maintaining stability.

**Next Steps**:
1. Review and approve architectural changes
2. Begin Phase 1 implementation
3. Set up version control and CI/CD
4. Establish code review process
5. Plan deployment strategy
